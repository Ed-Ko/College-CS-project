{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice : In this hw I just use student-mat.csv as only dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data input\n",
    "\n",
    "    In this part I use import csv.reader to read the dataset, and then just put data into a list(because the csv.reader will return a lists of list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. data preprocessing\n",
    "\n",
    "    In this part I do seceral things to preprocess my data\n",
    "\n",
    "    1. To use binary and 5-level classification, I duplicate the math dataset twice\n",
    "    2. In order to use classification through sklearn model, I use one-hot encoding to change values of categorical feature to numerical feature(but without G3)\n",
    "        for example, the value of feature \"school\" are \"GP\" and \"MS\", then \"GP\" is change to \"1\"(type is int) and \"MS\" is change to \"2\"(type is int), and for safety I also change the type all the numerical number in the two lists of list into type int\n",
    "    3. the final part is to change the value of G3 respectively. For binary classification, the values of G3(students' final grade between 0 to 20) are changed to two strings(\"pass\" and \"fail\") depends on whether the final grade is less 10(grade will change to \"fail\") or not less than 10(value will change to \"pass\"). For 5-level classification, the values of G3 are changed to five strings(\"fail\", \"sufficient\", \"satisfactory\", \"good\",and \"excellent\") depends on the given score interval in spec\n",
    "\n",
    "\n",
    "\n",
    "|       country      |       fail         |     sufficient     |    satisfactory    |        good        |      excellent     |\n",
    "|:--------------------:|:--------------------:|:--------------------:|:--------------------:|:--------------------:|:--------------------:|\n",
    "| Portugal / Ireland |       0-9          |       10-11        |       12-13        |       14-15        |        16-20       |\n",
    "|       Ireland      |        A           |         B          |         C          |         D          |          E         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. model construction & 4. validation\n",
    "\n",
    "for the convenience to deal with validation and classification, I put them together and these models will have different dataset and classification mode as listed below\n",
    "\n",
    "### data split\n",
    "It's the first part of model construction. Because the dataset in data preprocessing section doesn't separate G3 from other features. So for this part I first finish separating it. Both dataset used for binary classification and that used for 5-level classification are separated here.\n",
    "\n",
    "After that, I use train_test_split to split the two dataset for binay classification and 5-level classification into trainning dataset and testing dataset\n",
    "\n",
    "\n",
    "\n",
    "### model construction\n",
    "#### **notice : Because every time when a classifier in sklearn fit and it ever fit before, the previous record will be overwritten. Therefore I will keep using appropriate classifier as many times as possible**\n",
    "\n",
    "\n",
    "The classifier I used in this homework are all from scikit learn.\n",
    "- decision tree : the algorithm of classifier used in sklearn is CART instead of ID3\n",
    "- random forest : implemented with random forest classifier in sklearn\n",
    "- KNN : implemented with KNN neighbor classifier in sklearn\n",
    "\n",
    "For holdout validation and k-fold validation with respect to binary classification and 5-level classification , I use different method to implement them\n",
    "- holdout validation : dataset used in holdout validation is the trainning and test data from train_test_split of dataset of binary classification or 5-level classification\n",
    "- k-fold validation  : dataset used in k-fold validation is directly extracted from dataset for binary classification or that of 5-level classification\n",
    "\n",
    "\n",
    "\n",
    "To sum up, the model that would be used are listed below : \n",
    "\n",
    "1. Decision Tree\n",
    "- binary classification & holdout validation \n",
    "- binary classification & k-fold validation\n",
    "- 5-level classification & holdout validation\n",
    "- 5-level classification & k-fold validation\n",
    "\n",
    "2. Random forest\n",
    "\n",
    "For random forest, I used tree number equal to 10, 100 and 1000 for three models. Each model will do classification and validation as listed below\n",
    "- notice : So the difference between k-fold validation and random forest is that random forest use the result of many trees and voting to get an agreed predicted output, while k-fold validation is a way to use random subset of dataset to get multiple predicted accuracy and average them.\n",
    "\n",
    "- When tree number is 10:\n",
    "    - notice : for random forest I just used the shuffled data(because in spec we're asked to use either random number of features or random number of samples, so I think the shuffled data finished in data preprocessing is a kind of random samples)\n",
    "    - binary classification & holdout validation \n",
    "    - binary classification & k-fold validation\n",
    "    - 5-level classification & holdout validation\n",
    "    - 5-level classification & k-fold validation\n",
    "- When tree number is 100:\n",
    "    - binary classification & holdout validation \n",
    "    - binary classification & k-fold validation\n",
    "    - 5-level classification & holdout validation\n",
    "    - 5-level classification & k-fold validation\n",
    "- When tree number is 100:\n",
    "    - binary classification & holdout validation \n",
    "    - binary classification & k-fold validation\n",
    "    - 5-level classification & holdout validation\n",
    "    - 5-level classification & k-fold validation\n",
    "\n",
    "3. KNN\n",
    "- notice : In KNN I set k equals to 1,10 and 50 due to the amount of dataset size\n",
    "- When K is 1:\n",
    "    - binary classification & holdout validation \n",
    "    - binary classification & k-fold validation\n",
    "    - 5-level classification & holdout validation\n",
    "    - 5-level classification & k-fold validation\n",
    "- When K is 10:\n",
    "    - binary classification & holdout validation \n",
    "    - binary classification & k-fold validation\n",
    "    - 5-level classification & holdout validation\n",
    "    - 5-level classification & k-fold validation\n",
    "- When K is 50:\n",
    "    - binary classification & holdout validation \n",
    "    - binary classification & k-fold validation\n",
    "    - 5-level classification & holdout validation\n",
    "    - 5-level classification & k-fold validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. result\n",
    "\n",
    "The result of all required data can be seen in my program after running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. comparison & conclusion\n",
    "\n",
    "For comparison,first I would like to compare the accuracy of binary classification and 5-level classification.\n",
    "Because some interval of 5-level classification, like good or satisfactory, are too narrow. This might be the reason why the accuracy of 5-level classification are usually less than binary classification\n",
    "\n",
    "And the second thing is the accuracy of random forest models using different decision tree number. Because random forest use voting mechanism to choose the predicted outcome from multiple outcomes predicted by these decision trees, we can observe that tree number will influence the accuracy of random forest. The more the tree number is, the higher the accuracy is(if more tree have the same output, than the voted outcome is likely to be the correct answer) \n",
    "\n",
    "The third thing is that the accuracy of KNN under different k. The higher the k is, the lower the accuracy is(because the model will search too much neighbor to predict the given test dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. question\n",
    "\n",
    "### Decision tree\n",
    "\n",
    "- notice : for this part I only use holdout validation to explain the question of decision tree, but both binary classification and 5-level classification are presented in the program\n",
    "To predict an input sample, the outcome is shown in the graph of decision tree. Instead of split the dataset with the feature, which has highest inforamtion gain in that dataset and is categorical, and make tree nodes for each value, in all the decision tree model binary split is used to split the dataset on each node\n",
    "\n",
    "When a sample enter the trained decision tree model, it will follow the branch of tree graphs in my program to find the leaf node. That is, the leaf node which the sample goes to is the predicted outcome.\n",
    "\n",
    "\n",
    "\n",
    "### Random forest\n",
    "The difference of boosting and bagging is that, boosting aims to solve the underfitting problem while bagging aims to solve overfitting problem\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### KNN\n",
    "- notice : for KNN I only use holdout validation to explain the question of KNN, but both binary classification and 5-level classification are presented in the program\n",
    "To describe the decision boundary of KNN, here I use G1 and G2 in the dataset of students to draw the graph, and the outcome is the graph shown in my program after running\n",
    "\n",
    "When a sample enters, the classifier will find the G1 and G2 of the sample and try to find the most possible outcome as the answer under the limitation of decision boundaries\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
