{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "## 0716306 柯立恩\n",
    "\n",
    "## Explanation of code \n",
    "My code is divided into several parts and the order is same as the spec. \n",
    "1. data input : import some library and read .data file, put all the data in pandas framwork.\n",
    "\n",
    "2. data visualization : At first I calculate the accuracy, standard deviation, and data frequency of each feature(iris dataset). Following that is the data frequency of each feature of mushroom dataset. Only data frequency is shown in figure using matplotlib. This step is done through dictionary(data structure). I also use gridspec in matplotlib to group figures of mushroom feature(to decrease the size of each figure)\n",
    "\n",
    "3. data preprocessing\n",
    "    Drop features with any missing value : missing values are found in mushroom dataset(the feature is bruises, in the column 12), I drop it before put all the data into pandas dataframe\n",
    "    \n",
    "    Transform data format and shape so  model can process them : I put all the data into pandas dataframe, and change it into nested list if I need to do some operation with it.\n",
    "    \n",
    "    Shuffle the data : I only shuffle data when using k-fold, because I use train-test-split in sklearn.model_selection. This method in sklearn will randomly select test data and trainning data for me, that's why I didn't shuffle it when using holdout.\n",
    "\n",
    "4. model construction\n",
    "    I construct all the model through built-in classifer in python. For mushroom dataset I use Cateforical naive bayes classifier, and Gaussian naive bayes classifier for Iris dataset\n",
    "    \n",
    "5. train-test-split\n",
    "    For the reason of simplifying coding process, I put model construction and train-test-split together. Here I use train-test-split in sklearn.model_selection to split both Iris dataset and mushroom dataset to test data and trainning data with test data in 30% and trainning data in 70%, and then directly fit it. For k-fold cross validation, I read data from pandas dataframe and turn it into nested list before I suffle it. After that, the shuffled dataset is divided into 3 parts(because k=3 in spec) and each part of data will be used as test data once\n",
    "    btw I also put some variable in this section for use of data manipulation in result\n",
    "\n",
    "6. result\n",
    "    Because I already compute needed number for computing confusion matrix, recall, precision and accuracy(only k-fold, data needed for holdout is still compute in this section), so this section only does a few operation and print the table and number for requirement.\n",
    "    \n",
    "     btw because I think Iris data still have TP, TN, FP and FN(if the iris is allocated to the species it belongs to, then the result is TP, otherwise FN), so I produce the confusion matrix for Iris dataset\n",
    "\n",
    "7. comparison & conclusion\n",
    "    Comparison and conclusion is written in source code\n",
    "    \n",
    "8. question\n",
    "    All the answer to question can be found through running source code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
