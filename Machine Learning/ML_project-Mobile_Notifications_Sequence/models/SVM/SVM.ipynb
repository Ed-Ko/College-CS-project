{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. Data input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "questionaire_input = []\n",
    "\n",
    "# read statistical.csv\n",
    "with open('statistical.csv',encoding = 'utf-8',newline = '') as csvfile:\n",
    "     reader = csv.reader(csvfile,delimiter = ',')\n",
    "     for row in reader:\n",
    "        questionaire_input.append(row)"
   ]
  },
  {
   "source": [
    "# 2. Data preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "one hot encoding dictionary\n\ngender   {'女': 0, '男': 1}\nage   {'16～18歲': 0, '22～28歲': 1, '19～22歲': 2, '29歲以上': 3, '15歲以下': 4}\ndepartment   {'ee': 0, 'ed': 1, 'lb': 2, 'bi': 3, 'oe': 4, 'sc': 5, 'cs': 6, 'mg': 7, 'ot': 8}\ntotal_usetime   {'三至四小時': 0, '五小時以上': 1, '二至三小時': 2, '一小時以下': 3, '一至二小時': 4, '一至兩小時': 5}\nsocial_usetime   {'半至一小時': 0, '半小時以下': 1, '二至三小時': 2, '一至二小時': 3, '三小時以上': 4, '': 5}\ncommunication_usetime   {'半至一小時': 0, '三小時以上': 1, '一至二小時': 2, '': 3, '二至三小時': 4, '半小時以下': 5}\nentertainment_usetime   {'半至一小時': 0, '一至二小時': 1, '半小時以下': 2, '二至三小時': 3, '三小時以上': 4, '': 5}\nnews_usetime   {'半小時以下': 0, '半至一小時': 1, '': 2, '一至二小時': 3, '三小時以上': 4}\nsystem_usetime   {'半小時以下': 0, '': 1, '半至一小時': 2, '一至二小時': 3}\nnotification_usetime   {'半小時以下': 0, '半至一小時': 1, '': 2, '一至二小時': 3, '二至三小時': 4}\nview_order_top   {'最先看': 0, '最後看': 1, '中': 2}\nview_order_middle   {'中': 0, '最後看': 1, '最先看': 2}\nview_order_bottom   {'最後看': 0, '中': 1, '最先看': 2}\nscenario   {'working': 0, 'resting': 1, 'commuting': 2, 'wakingup': 3}\n"
     ]
    }
   ],
   "source": [
    "# use one-hot encoding to transform the string to number in each feature\n",
    "\n",
    "# make dictionary for encoding(not include tolerance label)\n",
    "feature_dict = {}\n",
    "for i in range(0,14):\n",
    "    feature_dict[questionaire_input[0][i]] = {}\n",
    "\n",
    "for i in range(1,len(questionaire_input)):\n",
    "    for j in range(0,14):\n",
    "        feature_now = questionaire_input[0][j] # the feature of current element\n",
    "        if not isinstance(questionaire_input[i][j],int): # just used for test\n",
    "            if questionaire_input[i][j] not in feature_dict[feature_now]:\n",
    "        \n",
    "                # use difference number to identify each value\n",
    "                feature_dict[feature_now][questionaire_input[i][j]] = len(feature_dict[feature_now]) \n",
    "                questionaire_input[i][j] = feature_dict[feature_now][questionaire_input[i][j]] # change the value type of feature from str to int\n",
    "            else:\n",
    "                questionaire_input[i][j] = feature_dict[feature_now][questionaire_input[i][j]]\n",
    "\n",
    "# list the dictionary of one-hot encoding below\n",
    "print(\"one hot encoding dictionary\\n\")\n",
    "for key in feature_dict:\n",
    "    print(key,\" \",feature_dict[key])\n"
   ]
  },
  {
   "source": [
    "# 3. Model construction\n",
    "\n",
    "參數:\n",
    "宣告SVM model時\n",
    "svm_model_name = svm.SVC(C = float(number),kernel = 'kernel_name', gamma = float(number))\n",
    "p.s : SVM會使用不同的kernel function, 我用一個dictionary存放4個不同kernel function的SVM，名稱是svm_dict\n",
    "\n",
    "validation參數\n",
    "1. holdout validation : test ratio = 0.125\n",
    "\n",
    "2. k-fold validation : k = 2\n",
    "\n",
    "SVM模型參數\n",
    "1. C = 100 (僅開放rbf和poly，用在linear和sigmoid會跑很久)\n",
    "\n",
    "2. gamma = 0.1(僅開放rbf和poly(大概要跑6小時)，gamma為初始值時跑比較快(30分鐘)，用在linear和sigmoid會跑很久)\n",
    "  其他參數則為初始值\n",
    "\n",
    "觀察:\n",
    "\n",
    "1. 無論使用的validation，rbf為kernel function時通常會有最高的accuracy(有時polynomial會佔據最高accuracy)\n",
    "\n",
    "2. 當SVM中的參數 C = 100.0 時有最好的整體accuracy(約能提升1%到3%)，整體accuracy在C變大和變小時遞減\n",
    "\n",
    "3. 當SVM中的參數 gamma = 0.1 時有最好的整體accuracy\n",
    "\n",
    "4. SVM的參數gamma對整體的accuracy的提升影響微弱，甚至會降低一些accuracy\n",
    "\n",
    "p.s : C和gamma的參數調控只限於rbf和polynomial，linear和sigmoid不適用(你可以試試看，但我試了之後跑了一個晚上加一個上午還沒跑完，然後gamma=0.1時用於rbf和poly時用了大概6小時跑完)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "holdout validation with test ratio = 0.125\n",
      "\n",
      "========================\n",
      "  accuracy of 1 1 1 1 1 1:\n",
      "     linear  :  0.14528301886792452 \n",
      "\n",
      "     poly  :  0.19905660377358492 \n",
      "\n",
      "     rbf  :  0.23867924528301887 \n",
      "\n",
      "     sigmoid  :  0.04433962264150943 \n",
      "\n",
      "========================\n",
      "  accuracy of 1 1 2 2:\n",
      "     linear  :  0.15849056603773584 \n",
      "\n",
      "     poly  :  0.2490566037735849 \n",
      "\n",
      "     rbf  :  0.2971698113207547 \n",
      "\n",
      "     sigmoid  :  0.10471698113207546 \n",
      "\n",
      "========================\n",
      "  accuracy of 1 2 3:\n",
      "     linear  :  0.21037735849056607 \n",
      "\n",
      "     poly  :  0.3169811320754717 \n",
      "\n",
      "     rbf  :  0.3584905660377358 \n",
      "\n",
      "     sigmoid  :  0.1330188679245283 \n",
      "\n",
      "========================\n",
      "  accuracy of 2 2 2:\n",
      "     linear  :  0.22830188679245284 \n",
      "\n",
      "     poly  :  0.28773584905660377 \n",
      "\n",
      "     rbf  :  0.31132075471698106 \n",
      "\n",
      "     sigmoid  :  0.16226415094339625 \n",
      "\n",
      "========================\n",
      "  accuracy of 2 4:\n",
      "     linear  :  0.440566037735849 \n",
      "\n",
      "     poly  :  0.4490566037735849 \n",
      "\n",
      "     rbf  :  0.4518867924528303 \n",
      "\n",
      "     sigmoid  :  0.35094339622641507 \n",
      "\n",
      "========================\n",
      "  accuracy of 1 5:\n",
      "     linear  :  0.5132075471698112 \n",
      "\n",
      "     poly  :  0.5877358490566038 \n",
      "\n",
      "     rbf  :  0.6084905660377358 \n",
      "\n",
      "     sigmoid  :  0.44811320754716977 \n",
      "\n",
      "========================\n",
      "the highest accuracy of 111111 :  0.23867924528301887 with kernel :  rbf\n",
      "the highest accuracy of 1122 :  0.2971698113207547 with kernel :  rbf\n",
      "the highest accuracy of 123 :  0.3584905660377358 with kernel :  rbf\n",
      "the highest accuracy of 222 :  0.31132075471698106 with kernel :  rbf\n",
      "the highest accuracy of 24 :  0.4518867924528303 with kernel :  rbf\n",
      "the highest probability of 15 :  0.6084905660377358 with kernel :  rbf\n",
      "========================\n",
      "\n",
      "k-fold validation with k = 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "========================\n",
      "  accuracy of 1 1 1 1 1 1:\n",
      "     linear  :  0.16026610893556426 \n",
      "\n",
      "     poly  :  0.20516642933428267 \n",
      "\n",
      "     rbf  :  0.2520914916340335 \n",
      "\n",
      "     sigmoid  :  0.0317061231755073 \n",
      "\n",
      "========================\n",
      "  accuracy of 1 1 2 2:\n",
      "     linear  :  0.1770870416518334 \n",
      "\n",
      "     poly  :  0.2700249199003204 \n",
      "\n",
      "     rbf  :  0.31007475970096116 \n",
      "\n",
      "     sigmoid  :  0.10742257030971876 \n",
      "\n",
      "========================\n",
      "  accuracy of 1 2 3:\n",
      "     linear  :  0.1889239943040228 \n",
      "\n",
      "     poly  :  0.3199759700961196 \n",
      "\n",
      "     rbf  :  0.3563323246707013 \n",
      "\n",
      "     sigmoid  :  0.14700516197935207 \n",
      "\n",
      "========================\n",
      "  accuracy of 2 2 2:\n",
      "     linear  :  0.24005428978284085 \n",
      "\n",
      "     poly  :  0.2968805624777501 \n",
      "\n",
      "     rbf  :  0.3245594517621929 \n",
      "\n",
      "     sigmoid  :  0.166562833748665 \n",
      "\n",
      "========================\n",
      "  accuracy of 2 4:\n",
      "     linear  :  0.450249199003204 \n",
      "\n",
      "     poly  :  0.47049661801352793 \n",
      "\n",
      "     rbf  :  0.46348789604841584 \n",
      "\n",
      "     sigmoid  :  0.33492791028835883 \n",
      "\n",
      "========================\n",
      "  accuracy of 1 5:\n",
      "     linear  :  0.5132831968672125 \n",
      "\n",
      "     poly  :  0.6164560341758634 \n",
      "\n",
      "     rbf  :  0.626379494482022 \n",
      "\n",
      "     sigmoid  :  0.4480687077251691 \n",
      "\n",
      "========================\n",
      "the highest accuracy of 111111 :  0.2520914916340335 with kernel :  rbf\n",
      "the highest accuracy of 1122 :  0.31007475970096116 with kernel :  rbf\n",
      "the highest accuracy of 123 :  0.3563323246707013 with kernel :  rbf\n",
      "the highest accuracy of 222 :  0.3245594517621929 with kernel :  rbf\n",
      "the highest accuracy of 24 :  0.47049661801352793 with kernel :  poly\n",
      "the highest accuracy of 15 :  0.626379494482022 with kernel :  rbf\n",
      "program execution time :  21001.403378725052\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "# try 4 different SVM model to test the difference\n",
    "svm_dict = {'linear' : svm.SVC(kernel='linear'),\n",
    "            'rbf' : svm.SVC(C=100,kernel='rbf',gamma=0.1),\n",
    "            'poly' : svm.SVC(C=100,kernel='poly',gamma=0.1),\n",
    "            'sigmoid': svm.SVC(kernel='sigmoid')}\n",
    "\n",
    "# change the data to numpy array\n",
    "questionaire_input = np.array(questionaire_input[1:])\n",
    "np.random.shuffle(questionaire_input)\n",
    "\n",
    "# choose the test ratio and k with highest accuracy with given test times\n",
    "\n",
    "test_time = 10\n",
    "test_ratio = 0.125\n",
    "k = 2\n",
    "\n",
    "\n",
    "# accuracy for each tolerance \n",
    "accuracy_111111 = {'linear':0,\n",
    "                   'poly':0,\n",
    "                   'rbf':0,\n",
    "                   'sigmoid':0}\n",
    "\n",
    "accuracy_1122 = {'linear':0,\n",
    "                 'poly':0,\n",
    "                 'rbf':0,\n",
    "                 'sigmoid':0}\n",
    "\n",
    "accuracy_123 = {'linear':0,\n",
    "                'poly':0,\n",
    "                'rbf':0,\n",
    "                'sigmoid':0}\n",
    "\n",
    "accuracy_222 = {'linear':0,\n",
    "                'poly':0,\n",
    "                'rbf':0,\n",
    "                'sigmoid':0}\n",
    "\n",
    "accuracy_24 = {'linear':0,\n",
    "               'poly':0,\n",
    "               'rbf':0,\n",
    "               'sigmoid':0}\n",
    "\n",
    "accuracy_15 = {'linear':0,\n",
    "               'poly':0,\n",
    "               'rbf':0,\n",
    "               'sigmoid':0}\n",
    "\n",
    "# confusion matrix\n",
    "'''\n",
    "confusion_hold_111111 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_hold_1122 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_hold_123 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_hold_222 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_hold_24 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_hold_15 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "\n",
    "confusion_kfold_111111 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_kfold_1122 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_kfold_123 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_kfold_222 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_kfold_24 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "confusion_kfold_15 = {'linear':[],'poly':[],'rbf':[],'sigmoid':[]}\n",
    "'''\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# X and y for each model\n",
    "X_111111 = questionaire_input[1:,0:14]\n",
    "y_111111 = questionaire_input[1:,14]\n",
    "\n",
    "X_1122 = questionaire_input[1:,0:14]\n",
    "y_1122 = questionaire_input[1:,15]\n",
    "\n",
    "X_123 = questionaire_input[1:,0:14]\n",
    "y_123 = questionaire_input[1:,16]\n",
    "\n",
    "X_222 = questionaire_input[1:,0:14]\n",
    "y_222 = questionaire_input[1:,17]\n",
    "\n",
    "X_24 = questionaire_input[1:,0:14]\n",
    "y_24 = questionaire_input[1:,18]\n",
    "\n",
    "X_15 = questionaire_input[1:,0:14]\n",
    "y_15 = questionaire_input[1:,19]\n",
    "\n",
    "print(\"holdout validation with test ratio = 0.125\\n\")\n",
    "for i in range(test_time):\n",
    "    # holdout data\n",
    "    train_x_111111, test_x_111111, train_y_1111111, test_y_111111 = train_test_split(X_111111,y_111111,test_size = 0.125)\n",
    "    train_x_1122, test_x_1122, train_y_1122, test_y_1122 = train_test_split(X_1122,y_1122,test_size = 0.125)\n",
    "    train_x_123, test_x_123, train_y_123, test_y_123 = train_test_split(X_123,y_123,test_size = 0.125)\n",
    "    train_x_222, test_x_222, train_y_222, test_y_222 = train_test_split(X_222,y_222,test_size = 0.125)\n",
    "    train_x_24, test_x_24, train_y_24, test_y_24 = train_test_split(X_24,y_24,test_size = 0.125)\n",
    "    train_x_15, test_x_15, train_y_15, test_y_15 = train_test_split(X_15,y_15,test_size = 0.125)\n",
    "\n",
    "    \n",
    "    for key in svm_dict:\n",
    "        # 1 1 1 1 1 1\n",
    "        svm_dict[key].fit(train_x_111111,train_y_1111111)\n",
    "        pred_y_111111 = svm_dict[key].predict(test_x_111111)\n",
    "        accuracy_111111[key] += accuracy_score(test_y_111111, pred_y_111111)\n",
    "        #confusion_hold_111111[key] += confusion_matrix(test_y_111111, pred_y_111111)\n",
    "\n",
    "\n",
    "        # 1 1 2 2\n",
    "        svm_dict[key].fit(train_x_1122,train_y_1122)\n",
    "        pred_y_1122 = svm_dict[key].predict(test_x_1122)\n",
    "        accuracy_1122[key] += accuracy_score(test_y_1122, pred_y_1122)\n",
    "        #confusion_hold_1122[key] += confusion_matrix(test_y_1122, pred_y_1122)\n",
    "\n",
    "        # 1 2 3\n",
    "        svm_dict[key].fit(train_x_123,train_y_123)\n",
    "        pred_y_123 = svm_dict[key].predict(test_x_123)\n",
    "        accuracy_123[key] += accuracy_score(test_y_123, pred_y_123)\n",
    "        #confusion_hold_123[key] += confusion_matrix(test_y_123, pred_y_123)\n",
    "\n",
    "        # 2 2 2\n",
    "        svm_dict[key].fit(train_x_222,train_y_222)\n",
    "        pred_y_222 = svm_dict[key].predict(test_x_222)\n",
    "        accuracy_222[key] += accuracy_score(test_y_222, pred_y_222)\n",
    "        #confusion_hold_123[key] += confusion_matrix(test_y_222, pred_y_222)\n",
    "\n",
    "        # 2 4\n",
    "        svm_dict[key].fit(train_x_24,train_y_24)\n",
    "        pred_y_24 = svm_dict[key].predict(test_x_24)\n",
    "        accuracy_24[key] += accuracy_score(test_y_24, pred_y_24)\n",
    "        #confusion_hold_24[key] += confusion_matrix(test_y_24, pred_y_24)\n",
    "\n",
    "        # 1 5\n",
    "        svm_dict[key].fit(train_x_15,train_y_15)\n",
    "        pred_y_15 = svm_dict[key].predict(test_x_15)\n",
    "        accuracy_15[key] += accuracy_score(test_y_15, pred_y_15)\n",
    "        #confusion_hold_15[key] += confusion_matrix(test_y_15, pred_y_15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        if key == 'rbf':\n",
    "            for i in range(len(svm_rbf_test)):\n",
    "                for j in range(6):\n",
    "                    if j == 0:\n",
    "                        svm_rbf_test[i].fit(train_x_111111,train_y_1111111)\n",
    "                        accuracy_rbf_test[i][j] += accuracy_score(test_y_111111,svm_rbf_test[i].predict(test_x_111111)) \n",
    "                    if j == 1:\n",
    "                        svm_rbf_test[i].fit(train_x_1122,train_y_1122)\n",
    "                        accuracy_rbf_test[i][j] += accuracy_score(test_y_1122,svm_rbf_test[i].predict(test_x_1122)) \n",
    "                    if j == 2:\n",
    "                        svm_rbf_test[i].fit(train_x_123,train_y_123)\n",
    "                        accuracy_rbf_test[i][j] += accuracy_score(test_y_123,svm_rbf_test[i].predict(test_x_123)) \n",
    "                    if j == 3:\n",
    "                        svm_rbf_test[i].fit(train_x_222,train_y_222)\n",
    "                        accuracy_rbf_test[i][j] += accuracy_score(test_y_222,svm_rbf_test[i].predict(test_x_222))\n",
    "                    if j == 4:\n",
    "                        svm_rbf_test[i].fit(train_x_24,train_y_24)\n",
    "                        accuracy_rbf_test[i][j] += accuracy_score(test_y_24,svm_rbf_test[i].predict(test_x_24))\n",
    "                    if j == 5:\n",
    "                        svm_rbf_test[i].fit(train_x_15,train_y_15)\n",
    "                        accuracy_rbf_test[i][j] += accuracy_score(test_y_15,svm_rbf_test[i].predict(test_x_15))\n",
    "\n",
    "\n",
    "        if key == 'poly':\n",
    "            for i in range(len(svm_poly_test)):\n",
    "                for j in range(6):\n",
    "                    if j == 0:\n",
    "                        svm_poly_test[i].fit(train_x_111111,train_y_1111111)\n",
    "                        accuracy_poly_test[i][j] += accuracy_score(test_y_111111,svm_poly_test[i].predict(test_x_111111)) \n",
    "                    if j == 1:\n",
    "                        svm_poly_test[i].fit(train_x_1122,train_y_1122)\n",
    "                        accuracy_poly_test[i][j] += accuracy_score(test_y_1122,svm_poly_test[i].predict(test_x_1122)) \n",
    "                    if j == 2:\n",
    "                        svm_poly_test[i].fit(train_x_123,train_y_123)\n",
    "                        accuracy_poly_test[i][j] += accuracy_score(test_y_123,svm_poly_test[i].predict(test_x_123)) \n",
    "                    if j == 3:\n",
    "                        svm_poly_test[i].fit(train_x_222,train_y_222)\n",
    "                        accuracy_poly_test[i][j] += accuracy_score(test_y_222,svm_poly_test[i].predict(test_x_222))\n",
    "                    if j == 4:\n",
    "                        svm_poly_test[i].fit(train_x_24,train_y_24)\n",
    "                        accuracy_poly_test[i][j] += accuracy_score(test_y_24,svm_poly_test[i].predict(test_x_24))\n",
    "                    if j == 5:\n",
    "                        svm_poly_test[i].fit(train_x_15,train_y_15)\n",
    "                        accuracy_poly_test[i][j] += accuracy_score(test_y_15,svm_poly_test[i].predict(test_x_15))\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for key in svm_dict:\n",
    "    confusion_hold_111111[key] /= test_time\n",
    "    confusion_hold_1122[key] /= test_time\n",
    "    confusion_hold_123[key] /= test_time\n",
    "    confusion_hold_222[key] /= test_time\n",
    "    confusion_hold_24[key] /= test_time\n",
    "    confusion_hold_15[key] /= test_time\n",
    "'''\n",
    "# print the accuracy of holdout\n",
    "print(\"========================\")\n",
    "\n",
    "print(\"  accuracy of 1 1 1 1 1 1:\")\n",
    "for key in accuracy_111111:\n",
    "    print(\"    \",key,\" : \",accuracy_111111[key]/test_time,\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 1 1 2 2:\")\n",
    "for key in accuracy_1122:\n",
    "    print(\"    \",key,\" : \",accuracy_1122[key]/test_time,\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 1 2 3:\")\n",
    "for key in accuracy_123:\n",
    "    print(\"    \",key,\" : \",accuracy_123[key]/test_time,\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 2 2 2:\")\n",
    "for key in accuracy_222:\n",
    "    print(\"    \",key,\" : \",accuracy_222[key]/test_time,\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 2 4:\")\n",
    "for key in accuracy_24:\n",
    "    print(\"    \",key,\" : \",accuracy_24[key]/test_time,\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 1 5:\")\n",
    "for key in accuracy_15:\n",
    "    print(\"    \",key,\" : \",accuracy_15[key]/test_time,\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "# print the kernel with highest probability\n",
    "max_proba_kernel_111111 = \"linear\"\n",
    "for key in accuracy_111111:\n",
    "    if accuracy_111111[max_proba_kernel_111111] < accuracy_111111[key]:\n",
    "        max_proba_kernel_111111 = key\n",
    "\n",
    "print(\"the highest accuracy of 111111 : \",accuracy_111111[max_proba_kernel_111111]/test_time,\"with kernel : \",max_proba_kernel_111111)\n",
    "\n",
    "max_proba_kernel_1122 = \"linear\"\n",
    "for key in accuracy_1122:\n",
    "    if accuracy_1122[max_proba_kernel_1122] < accuracy_1122[key]:\n",
    "        max_proba_kernel_1122 = key\n",
    "\n",
    "print(\"the highest accuracy of 1122 : \",accuracy_1122[max_proba_kernel_1122]/test_time,\"with kernel : \",max_proba_kernel_1122)\n",
    "\n",
    "\n",
    "max_proba_kernel_123 = \"linear\"\n",
    "for key in accuracy_123:\n",
    "    if accuracy_123[max_proba_kernel_123] < accuracy_123[key]:\n",
    "        max_proba_kernel_123 = key\n",
    "\n",
    "print(\"the highest accuracy of 123 : \",accuracy_123[max_proba_kernel_123]/test_time,\"with kernel : \",max_proba_kernel_123)\n",
    "\n",
    "\n",
    "max_proba_kernel_222 = \"linear\"\n",
    "for key in accuracy_222:\n",
    "    if accuracy_222[max_proba_kernel_222] < accuracy_222[key]:\n",
    "        max_proba_kernel_222 = key\n",
    "\n",
    "print(\"the highest accuracy of 222 : \",accuracy_222[max_proba_kernel_222]/test_time,\"with kernel : \",max_proba_kernel_222)\n",
    "\n",
    "\n",
    "max_proba_kernel_24 = \"linear\"\n",
    "for key in accuracy_24:\n",
    "    if accuracy_24[max_proba_kernel_24] < accuracy_24[key]:\n",
    "        max_proba_kernel_24 = key\n",
    "\n",
    "print(\"the highest accuracy of 24 : \",accuracy_24[max_proba_kernel_24]/test_time,\"with kernel : \",max_proba_kernel_24)\n",
    "\n",
    "\n",
    "max_proba_kernel_15 = \"linear\"\n",
    "for key in accuracy_15:\n",
    "    if accuracy_15[max_proba_kernel_15] < accuracy_15[key]:\n",
    "        max_proba_kernel_15 = key\n",
    "\n",
    "print(\"the highest accuracy of 15 : \",accuracy_15[max_proba_kernel_15]/test_time,\"with kernel : \",max_proba_kernel_15)\n",
    "\n",
    "\n",
    "'''\n",
    "# print confusion matrix\n",
    "plt.figure(figsize = (10,10))\n",
    "ax_hold_111111 = sn.heatmap(confusion_hold_111111[max_proba_kernel_111111])\n",
    "ax_hold_111111.set_title(\"1 1 1 1 1 1 with test ratio = 0.125 & kernel = \",max_proba_kernel_111111)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "ax_hold_1122 = sn.heatmap(confusion_hold_1122[max_proba_kernel_1122])\n",
    "ax_hold_1122.set_title(\"1 1 2 2 with test ratio = 0.125 & kernel = \",max_proba_kernel_1122)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "ax_hold_123 = sn.heatmap(confusion_hold_123[max_proba_kernel_123])\n",
    "ax_hold_123.set_title(\"1 2 3 with test ratio = 0.125 & kernel = \",max_proba_kernel_123)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "ax_hold_222 = sn.heatmap(confusion_hold_222[max_proba_kernel_222])\n",
    "ax_hold_222.set_title(\"2 2 2 with test ratio = 0.125 & kernel = \",max_proba_kernel_222)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "ax_hold_24 = sn.heatmap(confusion_hold_24[max_proba_kernel_24])\n",
    "ax_hold_24.set_title(\"2 4 with test ratio = 0.125 & kernel = \",max_proba_kernel_24)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "ax_hold_15 = sn.heatmap(confusion_hold_15[max_proba_kernel_15])\n",
    "ax_hold_15.set_title(\"1 5 with test ratio = 0.125 & kernel = \",max_proba_kernel_15)\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "print(\"========================\\n\")\n",
    "\n",
    "print(\"k-fold validation with k = 2\\n\")\n",
    "\n",
    "# k-fold\n",
    "for i in range(1,len(questionaire_input),k):\n",
    "\n",
    "    # k-fold data for 1 1 1 1 1 1\n",
    "    train_x_now_111111 = np.concatenate((questionaire_input[:i,0:14],questionaire_input[i+k:,0:14]))\n",
    "    train_y_now_111111 = np.concatenate((questionaire_input[:i,14],questionaire_input[i+k:,14]))\n",
    "    test_x_now_111111 = questionaire_input[i:i+k,0:14]\n",
    "    test_y_now_111111 = questionaire_input[i:i+k,14]\n",
    "\n",
    "    for key in svm_dict:\n",
    "        svm_dict[key].fit(train_x_now_111111,train_y_now_111111)\n",
    "        pred_y_111111 = svm_dict[key].predict(test_x_now_111111)\n",
    "        accuracy_111111[key] += accuracy_score(test_y_now_111111,pred_y_111111)\n",
    "        #confusion_kfold_111111[key] += confusion_matrix(test_y_now_111111,pred_y_111111)\n",
    "\n",
    "\n",
    "\n",
    "    # k-fold data for 1 1 2 2 \n",
    "    train_x_now_1122 = np.concatenate((questionaire_input[:i,0:14],questionaire_input[i+k:,0:14]))\n",
    "    train_y_now_1122 = np.concatenate((questionaire_input[:i,15],questionaire_input[i+k:,15]))\n",
    "    test_x_now_1122 = questionaire_input[i:i+k,0:14]\n",
    "    test_y_now_1122 = questionaire_input[i:i+k,15]\n",
    "\n",
    "    for key in svm_dict:\n",
    "        svm_dict[key].fit(train_x_now_1122,train_y_now_1122)\n",
    "        pred_y_1122 = svm_dict[key].predict(test_x_now_1122)\n",
    "        accuracy_1122[key] += accuracy_score(test_y_now_1122,pred_y_1122)\n",
    "        #confusion_kfold_1122[key] += confusion_matrix(test_y_now_1122,pred_y_1122)\n",
    "\n",
    "    # k-fold data for 1 2 3\n",
    "    train_x_now_123 = np.concatenate((questionaire_input[:i,0:14],questionaire_input[i+k:,0:14]))\n",
    "    train_y_now_123 = np.concatenate((questionaire_input[:i,16],questionaire_input[i+k:,16]))\n",
    "    test_x_now_123 = questionaire_input[i:i+k,0:14]\n",
    "    test_y_now_123 = questionaire_input[i:i+k,16]\n",
    "\n",
    "    for key in svm_dict:\n",
    "        svm_dict[key].fit(train_x_now_123,train_y_now_123)\n",
    "        pred_y_123 = svm_dict[key].predict(test_x_now_123)\n",
    "        accuracy_123[key] += accuracy_score(test_y_now_123,pred_y_123)\n",
    "        #confusion_kfold_123[key] += confusion_matrix(test_y_now_123,pred_y_123)\n",
    "\n",
    "\n",
    "    # k-fold data for 2 2 2 \n",
    "    train_x_now_222 = np.concatenate((questionaire_input[:i,0:14],questionaire_input[i+k:,0:14]))\n",
    "    train_y_now_222 = np.concatenate((questionaire_input[:i,17],questionaire_input[i+k:,17]))\n",
    "    test_x_now_222 = questionaire_input[i:i+k,0:14]\n",
    "    test_y_now_222 = questionaire_input[i:i+k,17]\n",
    "\n",
    "    for key in svm_dict:\n",
    "        svm_dict[key].fit(train_x_now_222,train_y_now_222)\n",
    "        pred_y_222 = svm_dict[key].predict(test_x_now_222)\n",
    "        accuracy_222[key] += accuracy_score(test_y_now_222,pred_y_222)\n",
    "        #confusion_kfold_222[key] += confusion_matrix(test_y_now_222,pred_y_222)\n",
    "\n",
    "    # k-fold data for 2 4 \n",
    "    train_x_now_24 = np.concatenate((questionaire_input[:i,0:14],questionaire_input[i+k:,0:14]))\n",
    "    train_y_now_24 = np.concatenate((questionaire_input[:i,18],questionaire_input[i+k:,18]))\n",
    "    test_x_now_24 = questionaire_input[i:i+k,0:14]\n",
    "    test_y_now_24 = questionaire_input[i:i+k,18]\n",
    "\n",
    "    for key in svm_dict:\n",
    "        svm_dict[key].fit(train_x_now_24,train_y_now_24)\n",
    "        pred_y_24 = svm_dict[key].predict(test_x_now_24)\n",
    "        accuracy_24[key] += accuracy_score(test_y_now_24,pred_y_24)\n",
    "        #confusion_kfold_24[key] += confusion_matrix(test_y_now_24,pred_y_24)\n",
    "\n",
    "        \n",
    "\n",
    "    # k-fold data for 1 5 \n",
    "    train_x_now_15 = np.concatenate((questionaire_input[:i,0:14],questionaire_input[i+k:,0:14]))\n",
    "    train_y_now_15 = np.concatenate((questionaire_input[:i,19],questionaire_input[i+k:,19]))\n",
    "    test_x_now_15 = questionaire_input[i:i+k,0:14]\n",
    "    test_y_now_15 = questionaire_input[i:i+k,19]\n",
    "\n",
    "    for key in svm_dict:\n",
    "        svm_dict[key].fit(train_x_now_15,train_y_now_15)\n",
    "        pred_y_15 = svm_dict[key].predict(test_x_now_15)\n",
    "        accuracy_15[key] += accuracy_score(test_y_now_15,pred_y_15)\n",
    "        #confusion_kfold_15[key] += confusion_matrix(test_y_now_15,pred_y_15)\n",
    "'''\n",
    "for key in svm_dict:\n",
    "    confusion_kfold_111111[key] /= k\n",
    "    confusion_kfold_1122[key] /= k\n",
    "    confusion_kfold_123[key] /= k\n",
    "    confusion_kfold_222[key] /= k\n",
    "    confusion_kfold_24[key] /= k\n",
    "    confusion_kfold_15[key] /= k\n",
    "'''\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "print(\"  accuracy of 1 1 1 1 1 1:\")\n",
    "for key in accuracy_111111:\n",
    "    print(\"    \",key,\" : \",accuracy_111111[key]/int(len(questionaire_input)/k),\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 1 1 2 2:\")\n",
    "for key in accuracy_1122:\n",
    "    print(\"    \",key,\" : \",accuracy_1122[key]/int(len(questionaire_input)/k),\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 1 2 3:\")\n",
    "for key in accuracy_123:\n",
    "    print(\"    \",key,\" : \",accuracy_123[key]/int(len(questionaire_input)/k),\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 2 2 2:\")\n",
    "for key in accuracy_222:\n",
    "    print(\"    \",key,\" : \",accuracy_222[key]/int(len(questionaire_input)/k),\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 2 4:\")\n",
    "for key in accuracy_24:\n",
    "    print(\"    \",key,\" : \",accuracy_24[key]/int(len(questionaire_input)/k),\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "print(\"  accuracy of 1 5:\")\n",
    "for key in accuracy_15:\n",
    "    print(\"    \",key,\" : \",accuracy_15[key]/int(len(questionaire_input)/k),\"\\n\")\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "# print the kernel with highest probability\n",
    "max_proba_kernel_111111 = \"linear\"\n",
    "for key in accuracy_111111:\n",
    "    if accuracy_111111[max_proba_kernel_111111] < accuracy_111111[key]:\n",
    "        max_proba_kernel_111111 = key\n",
    "\n",
    "print(\"the highest accuracy of 111111 : \",accuracy_111111[max_proba_kernel_111111]/int(len(questionaire_input)/k),\"with kernel : \",max_proba_kernel_111111)\n",
    "\n",
    "max_proba_kernel_1122 = \"linear\"\n",
    "for key in accuracy_1122:\n",
    "    if accuracy_1122[max_proba_kernel_1122] < accuracy_1122[key]:\n",
    "        max_proba_kernel_1122 = key\n",
    "\n",
    "print(\"the highest accuracy of 1122 : \",accuracy_1122[max_proba_kernel_1122]/int(len(questionaire_input)/k),\"with kernel : \",max_proba_kernel_1122)\n",
    "\n",
    "\n",
    "max_proba_kernel_123 = \"linear\"\n",
    "for key in accuracy_123:\n",
    "    if accuracy_123[max_proba_kernel_123] < accuracy_123[key]:\n",
    "        max_proba_kernel_123 = key\n",
    "\n",
    "print(\"the highest accuracy of 123 : \",accuracy_123[max_proba_kernel_123]/int(len(questionaire_input)/k),\"with kernel : \",max_proba_kernel_123)\n",
    "\n",
    "\n",
    "max_proba_kernel_222 = \"linear\"\n",
    "for key in accuracy_222:\n",
    "    if accuracy_222[max_proba_kernel_222] < accuracy_222[key]:\n",
    "        max_proba_kernel_222 = key\n",
    "\n",
    "print(\"the highest accuracy of 222 : \",accuracy_222[max_proba_kernel_222]/int(len(questionaire_input)/k),\"with kernel : \",max_proba_kernel_222)\n",
    "\n",
    "\n",
    "max_proba_kernel_24 = \"linear\"\n",
    "for key in accuracy_24:\n",
    "    if accuracy_24[max_proba_kernel_24] < accuracy_24[key]:\n",
    "        max_proba_kernel_24 = key\n",
    "\n",
    "print(\"the highest accuracy of 24 : \",accuracy_24[max_proba_kernel_24]/int(len(questionaire_input)/k),\"with kernel : \",max_proba_kernel_24)\n",
    "\n",
    "\n",
    "max_proba_kernel_15 = \"linear\"\n",
    "for key in accuracy_15:\n",
    "    if accuracy_15[max_proba_kernel_15] < accuracy_15[key]:\n",
    "        max_proba_kernel_15 = key\n",
    "\n",
    "print(\"the highest accuracy of 15 : \",accuracy_15[max_proba_kernel_15]/int(len(questionaire_input)/k),\"with kernel : \",max_proba_kernel_15)\n",
    "\n",
    "'''\n",
    "print(\"========================\")\n",
    "\n",
    "\n",
    "for i in range(len(accuracy_rbf_test)):\n",
    "    for j in range(6):\n",
    "        print(accuracy_rbf_test[i][0]/test_time,\" \",accuracy_rbf_test[i][1]/test_time,\" \",accuracy_rbf_test[i][2]/test_time,\" \",accuracy_rbf_test[i][3]/test_time,\" \",accuracy_rbf_test[i][4]/test_time,\" \",accuracy_rbf_test[i][5]/test_time)\n",
    "\n",
    "\n",
    "print(\"\\n ======================== \\n\")\n",
    "for i in range(len(accuracy_poly_test)):\n",
    "    for j in range(6):\n",
    "        print(accuracy_poly_test[i][0]/test_time,\" \",accuracy_poly_test[i][1]/test_time,\" \",accuracy_poly_test[i][2]/test_time,\" \",accuracy_poly_test[i][3]/test_time,\" \",accuracy_poly_test[i][4]/test_time,\" \",accuracy_poly_test[i][5]/test_time)\n",
    "'''\n",
    "\n",
    "\n",
    "finish_time = time.time() - start_time\n",
    "print(\"program execution time : \",finish_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}